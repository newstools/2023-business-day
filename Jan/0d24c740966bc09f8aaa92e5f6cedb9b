Sci-fi authors of yesteryear postulated that 21st century roads would be filled with self-driving cars. Two decades into the century and we still haven’t achieved this utopian ideal, with the technology proving harder to achieve than earlier thought. Despite the impressive AI strides made by ChatGPT (try out this chatbot if you haven’t yet; your mind will be blown), getting fully robotised cars into the mainstream still has some tech hurdles to overcome. Around five years ago the idea of autonomous cars hit its peak, with automotive firms convincing us we would soon be able to watch movies or catch up on emails while vehicles safely drove us to our destinations. Carmakers have taken a step back from this after the full implications of such a scheme have become apparent. It’s one thing to get it right when all the cars on the roads are driven by artificial intelligence, but it’s much more difficult — and expensive — to program such cars to share the roads with capricious human-controlled vehicles. There are certain cities where fully self-driving taxis have begun operating in the US and China, but these are places where human drivers generally respect the rules of the road and the traffic lights are working. Can you imagine an AI-controlled vehicle trying to deal with load-shedding at traffic lights, informal pointsmen directing traffic, and the colourful driving habits of SA’s minibus taxis? The car would fry its microchips. The technical challenges and high costs of developing self-driving cars were underlined when Ford and Volkswagen recently shut down Argo AI, their multibillion-dollar joint autonomous car project, saying that profitable, fully autonomous vehicles at scale are a long way off. For now, despite what Elon Musk claims about his Teslas having an “autopilot” feature, carmakers are concentrating on perfecting so-called level 3 driving autonomy which allows a car to operate itself in certain controlled conditions, but with the driver always ready to take control. It differs from level 2 where a car has the ability to keep a safe following distance and stay in its lane, but a driver must constantly keep their hands on the wheel and monitor the environment. While AI cars aren’t quite ready to handle mass traffic yet, they are becoming more anthropomorphic and getting better at interacting one-on-one with us. The motor industry is making technology more human with voice-controlled virtual assistants, with some brands even programming “emotion” into their vehicles. Toyota’s 2017 Concept-i winks at passengers via the headlights when they approach. With what Toyota describes as a friendlier, people-focused approach to future mobility, the concept car’s advanced AI is able to measure emotion and “build a meaningful and human” relationship with the vehicle’s occupants. Honda’s NeuV concept car “measures” a driver’s emotions and moods via a heart-rate monitor in the seat and facial recognition. Represented by an emoji-like face on the dashboard screen, the virtual assistant pays attention to your likes and dislikes. If it senses you’re grumpy — for instance when you’ve been cut off by a minibus taxi — it might suggest switching on soothing classical music. The 2023 BMW i Vision Dee (it stands for “Digital Emotional Experience”) concept car talks back like KITT from the 1980s TV show Knight Rider, and its headlights and closed kidney grille form a phygital (fusion of physical and digital) icon, allowing the vehicle to produce different facial expressions. The i Vision Dee also has the ability to change colour like a chameleon. Tired of silver? Press a button and the car’s exterior can be changed to a wide palette of different colours and patterns using “E Ink” instead of paint. As we head towards a future of self-driven vehicles, the days of getting excitement from the driving experience itself are numbered. The next evolution in our relationship with cars involves giving them a different kind of personality. 